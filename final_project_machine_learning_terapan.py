# -*- coding: utf-8 -*-
"""Final Project - Machine Learning Terapan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17quC0G8DMNOezD8B5gFcRV07KdDpJG8v

# Import Library & Load File
"""

!pip install scikit-surprise

import ast
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from nltk.corpus import stopwords
from wordcloud import WordCloud, STOPWORDS

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity

from surprise import Reader, Dataset, SVD
from surprise.model_selection import cross_validate
import warnings; warnings.simplefilter('ignore')

# Menghubungkan notebook dengan Google Drive

from google.colab import drive
drive.mount('/content/drive/', force_remount = True)

movies_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Movies/movies_metadata.csv')

movies_df.head()

movies_df.info()

"""# Exploratory Data Analysis (EDA)"""

movies_df['title'] = movies_df['title'].astype('str')
movies_df['overview'] = movies_df['overview'].astype('str')

title_corpus = ' '.join(movies_df['title'])
overview_corpus = ' '.join(movies_df['overview'])

# Melihat kata yang sering muncul dalam setiap judul Film

title_wc = WordCloud(stopwords=STOPWORDS, background_color='black', height=2000, width=4000).generate(title_corpus)
plt.figure(figsize=(16,8))
plt.imshow(title_wc)
plt.axis('off')
plt.show()

# Melihat kata yang sering muncul dalam setiap Deskripsi Film

overview_wc = WordCloud(stopwords=STOPWORDS, background_color='black', height=2000, width=4000).generate(overview_corpus)
plt.figure(figsize=(16,8))
plt.imshow(overview_wc)
plt.axis('off')
plt.show()

# Mendefinisikan fungsi anotasi banyaknya data pada visualisasi

def show_values(axs, orient="v", space=.01):
    def _single(ax):
        if orient == "v":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() / 2
                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)
                value = '{:.1f}'.format(p.get_height())
                ax.text(_x, _y, value, ha="center")
        elif orient == "h":
            for p in ax.patches:
                _x = p.get_x() + p.get_width() + float(space)
                _y = p.get_y() + p.get_height() - (p.get_height()*0.5)
                value = '{:.1f}'.format(p.get_width())
                ax.text(_x, _y, value, ha="left")

    if isinstance(axs, np.ndarray):
        for idx, ax in np.ndenumerate(axs):
            _single(ax)
    else:
        _single(axs)

# Mengambil nama negara asal Film

movies_df['country'] = movies_df['production_countries'].fillna('[]').apply(ast.literal_eval)
movies_df['country'] = movies_df['country'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])
movies_df['country'].head()

s = movies_df.apply(lambda x: pd.Series(x['country']),axis=1).stack().reset_index(level=1, drop=True)
s.name = 'country'

movies_df = movies_df.drop('country', axis=1).join(s)
movies_df['country'] = movies_df['country'].replace('United States of America', 'USA')
movies_df['country'] = movies_df['country'].replace('United Kingdom', 'UK')

# Eksplor 10 negara asal Film terbanyak

countries = movies_df['country'].value_counts().sort_values(ascending=False).head(10)
countries = pd.DataFrame(countries)
countries = countries.reset_index()

# Plotting
sns.set()
plt.figure(figsize=(15, 7))
con_plt = sns.barplot(x='index', y='country', data=countries)

show_values(con_plt, 'v', space=0)

plt.xlabel("\n Production Countries")
plt.ylabel("Number of Production Countries")
plt.title("Top 10 Movies Production Countries\n")
plt.show()

movies_df['company'] = movies_df['production_companies'].fillna('[]').apply(ast.literal_eval)
movies_df['company'] = movies_df['company'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])
movies_df['company']

c = movies_df.apply(lambda x: pd.Series(x['company']),axis=1).stack().reset_index(level=1, drop=True)
c.name = 'company'
movies_df = movies_df.drop('company', axis=1).join(c)

# Eksplor 10 studio produsen Film terbanyak

company = movies_df['company'].value_counts().sort_values(ascending=False).head(10)
company = pd.DataFrame(company)
company = company.reset_index()

# Plotting
sns.set()
plt.figure(figsize=(20, 8))
com_plt = sns.barplot(x='company', y='index', data=company, orient='h')

show_values(com_plt, "h", space=0)

plt.xlabel("\n Production Companies")
plt.ylabel("Number of Production Companies")
plt.title("Top 10 Movies Production Companies\n")
plt.show()

"""# Data Preparation"""

# Load dataset Links
links_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Movies/links_small.csv')
links_df = links_df[links_df['tmdbId'].notnull()]['tmdbId'].astype('int')
links_df.head()

# Menambahkan kolom 'year'
movies_df['year'] = pd.to_datetime(movies_df['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)

movies_df = movies_df.drop([19730, 29503, 35587])

movies_df['id'] = movies_df['id'].astype('int')

mov_link = movies_df[movies_df['id'].isin(links_df)]

mov_link.drop_duplicates(subset=['title', 'overview'], inplace=True)

mov_link.shape

mov_link['mov_genre'] = mov_link['genres'].fillna('[]').apply(ast.literal_eval)

# Ekstrak 'name' dari list of dictionary di kolom 'genres'
mov_link['mov_genre'] = mov_link['mov_genre'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])

mov_link['mov_genre'].head()

mov_link['tagline'] = mov_link['tagline'].fillna('')
mov_link['description'] = mov_link['overview'] + mov_link['tagline']
mov_link['description'] = mov_link['description'].fillna('')

# Tokenizing setiap kata dalam corpus

tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')
tfidf_matrix = tfidf.fit_transform(mov_link['description'])

tfidf_matrix.shape

"""# Model Training"""

# Menghitung cosine similarity

cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
cosine_sim[1]

mov_link = mov_link.reset_index()
titles = mov_link['title']
indices = pd.Series(mov_link.index, index=mov_link['title'])

reader = Reader()

ratings = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Movies/ratings_small.csv')
ratings.head()

data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Inisiasi dan evaluasi model SVD dengan 5-fold cross-validation

svd = SVD()
cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

# Train model dengan semua data latih

trainset = data.build_full_trainset()
svd.fit(trainset)

"""# Hybrid Filtering (Mixed)"""

# Mendefinisikan fungsi konversi integer

def convert_int(x):
    try:
        return int(x)
    except:
        return np.nan

id_map = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Movies/links_small.csv')[['movieId', 'tmdbId']]
id_map['tmdbId'] = id_map['tmdbId'].apply(convert_int)
id_map.columns = ['movieId', 'id']
id_map = id_map.merge(mov_link[['title', 'id']], on='id').set_index('title')

indices_map = id_map.set_index('id')

# Fungsi Mixed Hybrid Recommendation
def hybrid_recommend(userId, title, n=5):
    idx = indices[title]
    tmdbId = id_map.loc[title]['id']
    movie_id = id_map.loc[title]['movieId']

    # Mendapatkan Top 25 Film yang mirip dengan judul input
    sim_score = list(enumerate(cosine_sim[int(idx)]))
    sim_score = sorted(sim_score, key=lambda x: x[1], reverse=True)
    sim_score = sim_score[1:30]
    movie_indices = [i[0] for i in sim_score]

    # Mencari film yang paling sesuai dengan pengguna
    movies = mov_link.iloc[movie_indices][['title', 'year', 'vote_count', 'vote_average', 'id', 'mov_genre']]
    movies['rating_est'] = movies['id'].apply(lambda x: svd.predict(userId, indices_map.loc[x]['movieId']).est)
    movies = movies.sort_values('rating_est', ascending=False)
    return movies.head(n)

hybrid_recommend(3000, 'Spectre', 10)

hybrid_recommend(404, 'Spectre', 10)

"""# Content-Based Filtering"""

def cb_recommend(title, n=5):
    idx = indices[title]
    tmdbId = id_map.loc[title]['id']
    movie_id = id_map.loc[title]['movieId']

    # Mendapatkan Top 30 Film yang mirip dengan judul input
    sim_score = list(enumerate(cosine_sim[int(idx)]))
    sim_score = sorted(sim_score, key=lambda x: x[1], reverse=True)
    sim_score = sim_score[1:30]
    movie_indices = [i[0] for i in sim_score]

    movies = mov_link.iloc[movie_indices][['title', 'year', 'vote_count', 'vote_average', 'id', 'mov_genre']]
    movies = movies.sort_values('vote_count', ascending=False)
    return movies.head(n)

mov_link['mov_genre'][mov_link['title'] == 'Spectre']

cb_recommend('Spectre', 10)

mov_link['mov_genre'][mov_link['title'] == 'Avengers: Age of Ultron']

cb_recommend('Avengers: Age of Ultron', 10)

